"""
è‚¡ç¥¨æ­·å²è³‡æ–™å¿«å–æœå‹™
====================
å°‡æŸ¥è©¢éçš„æ­·å²è³‡æ–™å­˜å…¥ PostgreSQLï¼Œå¤§å¹…æ¸›å°‘ Yahoo Finance API èª¿ç”¨

ç­–ç•¥ï¼š
1. é¦–æ¬¡æŸ¥è©¢ï¼šå¾ Yahoo æŠ“å–å®Œæ•´è³‡æ–™ä¸¦å­˜å…¥ DB
2. åŒæ—¥æŸ¥è©¢ï¼šç›´æ¥å¾ DB è®€å–ï¼ˆæ¯«ç§’ç´šï¼‰
3. éš”æ—¥æŸ¥è©¢ï¼šåªè£œæŠ“ç¼ºå¤±çš„æ—¥æœŸï¼ˆ1-3 ç§’ï¼‰

æ•ˆèƒ½é ä¼°ï¼š
- é¦–æ¬¡æŸ¥è©¢ï¼š10-30 ç§’ï¼ˆèˆ‡åŸä¾†ç›¸åŒï¼‰
- åŒæ—¥é‡æŸ¥ï¼š< 500msï¼ˆæå‡ 99%ï¼‰
- éš”æ—¥æŸ¥è©¢ï¼š1-3 ç§’ï¼ˆæå‡ 90%ï¼‰
"""
import pandas as pd
from datetime import datetime, date, timedelta
from typing import Optional, Tuple
from sqlalchemy.orm import Session
from sqlalchemy import select, and_, func, delete
from sqlalchemy.dialects.postgresql import insert
import logging

from app.models.stock_price import StockPrice
from app.data_sources.yahoo_finance import yahoo_finance

logger = logging.getLogger(__name__)


class StockHistoryService:
    """è‚¡ç¥¨æ­·å²è³‡æ–™å¿«å–æœå‹™"""
    
    def __init__(self, db: Session):
        self.db = db
    
    def get_stock_history(
        self,
        symbol: str,
        years: int = 10,
        force_refresh: bool = False,
    ) -> Tuple[Optional[pd.DataFrame], str]:
        """
        å–å¾—è‚¡ç¥¨æ­·å²è³‡æ–™ï¼ˆå„ªå…ˆä½¿ç”¨æœ¬åœ°å¿«å–ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            years: éœ€è¦çš„å¹´æ•¸ï¼ˆé è¨­ 10 å¹´ï¼‰
            force_refresh: æ˜¯å¦å¼·åˆ¶åˆ·æ–°
            
        Returns:
            (DataFrame, source) - source ç‚º 'cache', 'partial', 'yahoo'
        """
        symbol = symbol.upper()
        
        # å¼·åˆ¶åˆ·æ–°æ™‚ï¼Œç›´æ¥å¾ Yahoo æŠ“å–
        if force_refresh:
            logger.info(f"ğŸ”„ å¼·åˆ¶åˆ·æ–°: {symbol}")
            return self._fetch_and_save(symbol, years), "yahoo"
        
        # æª¢æŸ¥æœ¬åœ°å¿«å–
        cache_info = self._get_cache_info(symbol)
        
        if cache_info is None:
            # ç„¡å¿«å–ï¼Œé¦–æ¬¡æŸ¥è©¢
            logger.info(f"ğŸ“¥ é¦–æ¬¡æŸ¥è©¢: {symbol}")
            return self._fetch_and_save(symbol, years), "yahoo"
        
        latest_date, record_count = cache_info
        today = date.today()
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦è£œæŠ“
        if self._is_cache_fresh(latest_date, today):
            # å¿«å–æ˜¯æœ€æ–°çš„ï¼Œç›´æ¥è¿”å›
            logger.info(f"ğŸ“¦ å¿«å–å‘½ä¸­: {symbol} ({record_count} ç­†ï¼Œæœ€æ–° {latest_date})")
            df = self._load_from_db(symbol, years)
            return df, "cache"
        else:
            # éœ€è¦è£œæŠ“ç¼ºå¤±çš„æ—¥æœŸ
            days_missing = (today - latest_date).days
            logger.info(f"ğŸ“¥ è£œæŠ“ {symbol}: {days_missing} å¤© ({latest_date} â†’ {today})")
            
            # è£œæŠ“ä¸¦åˆä½µ
            df = self._fetch_incremental(symbol, latest_date, years)
            if df is not None and not df.empty:
                return df, "partial"
            else:
                # è£œæŠ“å¤±æ•—ï¼Œè¿”å›ç¾æœ‰è³‡æ–™
                df = self._load_from_db(symbol, years)
                return df, "cache"
    
    def _get_cache_info(self, symbol: str) -> Optional[Tuple[date, int]]:
        """
        å–å¾—å¿«å–è³‡è¨Š
        
        Returns:
            (æœ€æ–°æ—¥æœŸ, è¨˜éŒ„æ•¸) æˆ– None
        """
        stmt = select(
            func.max(StockPrice.date),
            func.count(StockPrice.id)
        ).where(StockPrice.symbol == symbol)
        
        result = self.db.execute(stmt).first()
        
        if result and result[0] is not None:
            return result[0], result[1]
        return None
    
    def _is_cache_fresh(self, latest_date: date, today: date) -> bool:
        """
        åˆ¤æ–·å¿«å–æ˜¯å¦è¶³å¤ æ–°
        
        è¦å‰‡ï¼š
        - æœ‰ä»Šæ—¥è³‡æ–™ â†’ æ–°é®®
        - é€±æœ«æ™‚æœ‰é€±äº”è³‡æ–™ â†’ æ–°é®®
        - å‡æ—¥æ™‚æœ‰æœ€è¿‘äº¤æ˜“æ—¥è³‡æ–™ â†’ æ–°é®®
        """
        if latest_date >= today:
            return True
        
        # é€±æœ«åˆ¤æ–·
        if today.weekday() >= 5:  # é€±å…­=5, é€±æ—¥=6
            # æ‰¾åˆ°æœ€è¿‘çš„é€±äº”
            days_since_friday = today.weekday() - 4
            last_friday = today - timedelta(days=days_since_friday)
            if latest_date >= last_friday:
                return True
        
        # å¦‚æœåªå·®ä¸€å¤©ï¼Œå¯èƒ½æ˜¯å‡æ—¥
        if (today - latest_date).days <= 1:
            return True
        
        return False
    
    def _fetch_and_save(self, symbol: str, years: int) -> Optional[pd.DataFrame]:
        """
        å¾ Yahoo Finance æŠ“å–å®Œæ•´è³‡æ–™ä¸¦å­˜å…¥ DB
        """
        period = f"{years}y"
        df = yahoo_finance.get_stock_history(symbol, period=period)
        
        if df is None or df.empty:
            return None
        
        # å­˜å…¥è³‡æ–™åº«
        saved = self._save_to_db(symbol, df)
        logger.info(f"ğŸ’¾ å·²å­˜å…¥ DB: {symbol} ({saved} ç­†)")
        
        return df
    
    def _fetch_incremental(
        self,
        symbol: str,
        last_date: date,
        years: int
    ) -> Optional[pd.DataFrame]:
        """
        å¢é‡æŠ“å–ï¼šåªæŠ“å–ç¼ºå¤±çš„æ—¥æœŸ
        """
        # è¨ˆç®—éœ€è¦æŠ“å–çš„å¤©æ•¸
        today = date.today()
        days_needed = (today - last_date).days + 5  # å¤šæŠ“å¹¾å¤©ç¢ºä¿å®Œæ•´
        
        # æŠ“å–æœ€è¿‘çš„è³‡æ–™
        if days_needed <= 30:
            period = "1mo"
        elif days_needed <= 90:
            period = "3mo"
        elif days_needed <= 180:
            period = "6mo"
        else:
            period = "1y"
        
        logger.info(f"ğŸ“¥ å¢é‡æŠ“å– {symbol}: period={period}")
        df_new = yahoo_finance.get_stock_history(symbol, period=period)
        
        if df_new is None or df_new.empty:
            logger.warning(f"âš ï¸ å¢é‡æŠ“å–å¤±æ•—: {symbol}")
            return None
        
        # åªä¿ç•™æ–°çš„è³‡æ–™
        df_new = df_new[df_new.index.date > last_date]
        
        if not df_new.empty:
            # å­˜å…¥è³‡æ–™åº«
            saved = self._save_to_db(symbol, df_new)
            logger.info(f"ğŸ’¾ å¢é‡å­˜å…¥: {symbol} ({saved} ç­†æ–°è³‡æ–™)")
        
        # è¿”å›å®Œæ•´è³‡æ–™
        return self._load_from_db(symbol, years)
    
    def _save_to_db(self, symbol: str, df: pd.DataFrame) -> int:
        """
        å­˜å…¥è³‡æ–™åº«ï¼ˆä½¿ç”¨ upsertï¼‰
        """
        if df is None or df.empty:
            return 0
        
        count = 0
        rows_to_insert = []
        
        for idx, row in df.iterrows():
            # è™•ç†æ—¥æœŸ
            if hasattr(idx, 'date'):
                row_date = idx.date()
            elif isinstance(idx, date):
                row_date = idx
            else:
                row_date = pd.to_datetime(idx).date()
            
            rows_to_insert.append({
                "symbol": symbol,
                "date": row_date,
                "open": float(row.get("open", row.get("Open", 0))) if pd.notna(row.get("open", row.get("Open"))) else None,
                "high": float(row.get("high", row.get("High", 0))) if pd.notna(row.get("high", row.get("High"))) else None,
                "low": float(row.get("low", row.get("Low", 0))) if pd.notna(row.get("low", row.get("Low"))) else None,
                "close": float(row.get("close", row.get("Close", 0))) if pd.notna(row.get("close", row.get("Close"))) else None,
                "volume": int(row.get("volume", row.get("Volume", 0))) if pd.notna(row.get("volume", row.get("Volume"))) else 0,
            })
        
        # æ‰¹é‡ upsert
        if rows_to_insert:
            for row in rows_to_insert:
                stmt = insert(StockPrice).values(**row)
                stmt = stmt.on_conflict_do_update(
                    index_elements=['symbol', 'date'],
                    set_={
                        'open': stmt.excluded.open,
                        'high': stmt.excluded.high,
                        'low': stmt.excluded.low,
                        'close': stmt.excluded.close,
                        'volume': stmt.excluded.volume,
                        'updated_at': func.now(),
                    }
                )
                try:
                    self.db.execute(stmt)
                    count += 1
                except Exception as e:
                    logger.warning(f"å­˜å…¥å¤±æ•— {symbol} {row['date']}: {e}")
            
            self.db.commit()
        
        return count
    
    def _load_from_db(self, symbol: str, years: int) -> Optional[pd.DataFrame]:
        """
        å¾è³‡æ–™åº«è¼‰å…¥æ­·å²è³‡æ–™
        """
        start_date = date.today() - timedelta(days=years * 365)
        
        stmt = (
            select(StockPrice)
            .where(
                and_(
                    StockPrice.symbol == symbol,
                    StockPrice.date >= start_date,
                )
            )
            .order_by(StockPrice.date)
        )
        
        results = self.db.execute(stmt).scalars().all()
        
        if not results:
            return None
        
        data = []
        for r in results:
            data.append({
                "date": r.date,
                "open": float(r.open) if r.open else None,
                "high": float(r.high) if r.high else None,
                "low": float(r.low) if r.low else None,
                "close": float(r.close) if r.close else None,
                "volume": r.volume,
            })
        
        df = pd.DataFrame(data)
        df.set_index('date', inplace=True)
        df.index = pd.to_datetime(df.index)
        
        return df
    
    def get_cache_stats(self, symbol: str = None) -> dict:
        """
        å–å¾—å¿«å–çµ±è¨ˆè³‡è¨Š
        """
        if symbol:
            info = self._get_cache_info(symbol.upper())
            if info:
                return {
                    "symbol": symbol.upper(),
                    "latest_date": info[0].isoformat(),
                    "record_count": info[1],
                    "is_fresh": self._is_cache_fresh(info[0], date.today()),
                }
            return {"symbol": symbol.upper(), "cached": False}
        
        # å…¨åŸŸçµ±è¨ˆ
        stmt = select(
            StockPrice.symbol,
            func.count(StockPrice.id),
            func.max(StockPrice.date)
        ).group_by(StockPrice.symbol)
        
        results = self.db.execute(stmt).all()
        
        return {
            "total_symbols": len(results),
            "total_records": sum(r[1] for r in results),
            "symbols": [
                {
                    "symbol": r[0],
                    "records": r[1],
                    "latest": r[2].isoformat() if r[2] else None,
                }
                for r in results
            ]
        }
    
    def clear_cache(self, symbol: str = None) -> int:
        """
        æ¸…é™¤å¿«å–
        
        Args:
            symbol: æŒ‡å®šè‚¡ç¥¨ä»£è™Ÿï¼ŒNone è¡¨ç¤ºæ¸…é™¤å…¨éƒ¨
            
        Returns:
            æ¸…é™¤çš„è¨˜éŒ„æ•¸
        """
        if symbol:
            stmt = delete(StockPrice).where(StockPrice.symbol == symbol.upper())
        else:
            stmt = delete(StockPrice)
        
        result = self.db.execute(stmt)
        self.db.commit()
        
        count = result.rowcount
        logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤å¿«å–: {symbol or 'å…¨éƒ¨'} ({count} ç­†)")
        return count


# ä¾¿æ·å‡½æ•¸
def get_stock_history_cached(
    db: Session,
    symbol: str,
    years: int = 10,
    force_refresh: bool = False
) -> Tuple[Optional[pd.DataFrame], str]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå–å¾—è‚¡ç¥¨æ­·å²è³‡æ–™ï¼ˆå¸¶å¿«å–ï¼‰
    """
    service = StockHistoryService(db)
    return service.get_stock_history(symbol, years, force_refresh)
